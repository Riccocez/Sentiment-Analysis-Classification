{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = \"https://www.trustpilot.com/review/www.rebtel.com\"\n",
    "link_ext = \"?page=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = [str(i) for i in range(2,107)]\n",
    "links =  [link] + [link + link_ext + i for i in pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract all data from all days\n",
    "all_reviews = []\n",
    "all_titles = []\n",
    "all_replies = []\n",
    "all_profiles = []\n",
    "all_ratings = []\n",
    "\n",
    "\n",
    "all_countries = [] #obtain from profiles\n",
    "all_reads = [] #obtain from profiles\n",
    "all_reviews = [] #obtain from profiles\n",
    "all_usefuls = [] #obtain from profiles\n",
    "all_review_times = [] #obtain from ratings\n",
    "\n",
    "#all_reply_times = [] #obtain from tmp_reply_times\n",
    "#all_likes = [] \n",
    "#all_updates = [] \n",
    "#all_genres = [] #obtain form profiles*\n",
    "\n",
    "for link in links:\n",
    "    \n",
    "    html = requests.get(link).text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    reviews = soup.findAll(\"div\",{\"class\": 'review-body'})\n",
    "    titles = soup.findAll(\"a\",{\"class\": 'review-title-link'})\n",
    "    profiles = soup.findAll(\"a\",{\"class\": 'user-review-name-link'})\n",
    "    ratings = soup.findAll(\"div\",{\"class\": 'review-info clearfix'})\n",
    "    tmp_reply_times = soup.findAll(\"div\",{\"class\": 'company-reply'})\n",
    "    replies = soup.findAll(\"div\",{\"class\": 'comment'})\n",
    "    \n",
    "    page_data = [reviews, titles, profiles, ratings, tmp_reply_times,replies]\n",
    "    all_reviews.append(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ratings = []\n",
    "all_review_times = []\n",
    "\n",
    "for page_reviews in all_reviews:\n",
    "    \n",
    "    page_ratings = []\n",
    "    page_times = []\n",
    "    \n",
    "    #get ratings and time_reviews per page\n",
    "    for rating_review in page_reviews[3]:\n",
    "        \n",
    "        rating = rating_review.contents[1].attrs['class'][1][-1]\n",
    "        time = rating_review.contents[3].attrs['title']\n",
    "        page_ratings.append(rating)\n",
    "        page_times.append(time)\n",
    "        \n",
    "    all_ratings.append(page_ratings)\n",
    "    all_review_times.append(page_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text_reviews = []\n",
    "all_title_reviews = []\n",
    "\n",
    "\n",
    "for page_reviews in all_reviews:\n",
    "    \n",
    "    page_text_reviews = []\n",
    "    page_title_reviews = []\n",
    "    \n",
    "    #get text reviews per page\n",
    "    for rating_review in page_reviews[0]:\n",
    "        \n",
    "        \n",
    "        raw_text = rating_review.contents[0]\n",
    "        text = raw_text.lstrip().rstrip()\n",
    "        page_text_reviews.append(text)\n",
    "        \n",
    "    all_text_reviews.append(page_text_reviews)\n",
    "        \n",
    "    #get title reviews per page\n",
    "    for rating_review in page_reviews[1]:\n",
    "        \n",
    "        title = rating_review.contents[0]\n",
    "        page_title_reviews.append(title)\n",
    "    all_title_reviews.append(page_title_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extended_profiles = []\n",
    "\n",
    "for page_reviews in all_reviews:\n",
    "    \n",
    "    profile_links = []\n",
    "    website = 'https://www.trustpilot.com/'\n",
    "    page_profiles = []\n",
    "    \n",
    "    #get profile links\n",
    "    for profile in page_reviews[2]:\n",
    "        \n",
    "        tmp_prof_link = website + profile.attrs['href']\n",
    "        profile_links.append(tmp_prof_link)\n",
    "        \n",
    "    \n",
    "    for link in profile_links:\n",
    "    \n",
    "        html = requests.get(link).text\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "        tmp_summ = soup.find(\"div\",{\"class\": 'user-summary-gender-location'})\n",
    "        country = tmp_summ.contents[-2].contents[0]\n",
    "    \n",
    "        tmp_name = soup.find(\"h1\",{\"class\": 'user-summary-info__user-name'})\n",
    "        user_name = tmp_name.contents[0]\n",
    "    \n",
    "        tmp_rev = soup.find(\"span\",{\"class\": 'user-reviews-stats__reviewcount'})\n",
    "        num_rev = tmp_rev.attrs['data-count']\n",
    "    \n",
    "        tmp_reads = soup.find(\"span\",{\"class\": 'user-reviews-stats__readcount'})\n",
    "        num_reads = tmp_reads.attrs['data-count']\n",
    "    \n",
    "        tmp_useful = soup.find(\"span\",{\"class\": 'user-reviews-stats__usefulcount'})\n",
    "        num_useful = tmp_useful.attrs['data-count']\n",
    "    \n",
    "        tmp_genre = soup.find(\"div\",{\"class\": 'user-summary-gender'})\n",
    "        genre = tmp_genre.contents[0]\n",
    "    \n",
    "        profile_data = [country, user_name, num_rev, num_reads, num_useful, genre]\n",
    "    \n",
    "        page_profiles.append(profile_data)\n",
    "    \n",
    "    extended_profiles.append(page_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing profile data\n",
    "for page_review in extended_profiles:\n",
    "    for profile in page_review:\n",
    "        \n",
    "        profile[1] = profile[1].rstrip().lstrip()\n",
    "        profile[-1] = profile[-1].rstrip().lstrip()\n",
    "        tmp_country = profile[0].rstrip().lstrip()\n",
    "        \n",
    "        if tmp_country.count(',') is 0:\n",
    "            profile[0] = tmp_country\n",
    "        else:\n",
    "            profile[0] = tmp_country.rsplit()[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile = extended_profiles[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = profile[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.count(',') is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing time data\n",
    "clean_time_reviews = []\n",
    "\n",
    "for page in all_review_times:\n",
    "    page_time_reviews = []\n",
    "    \n",
    "    for review_time in page:\n",
    "        ptime = parser.parse(review_time)\n",
    "        clean_time = [ptime.day,ptime.month,ptime.year,\n",
    "                      ptime.hour,ptime.minute,ptime.second,\n",
    "                      ptime.isoweekday(),ptime.isocalendar()[1],\n",
    "                      ptime.isoformat()]\n",
    "        page_time_reviews.append(clean_time)\n",
    "        \n",
    "    clean_time_reviews.append(page_time_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_data(collected_data):\n",
    "    \n",
    "    data = [item for sublist in collected_data for item in sublist]\n",
    "    return data\n",
    "\n",
    "ext_profiles_f =  flatten_data(extended_profiles)\n",
    "title_reviews_f = flatten_data(all_title_reviews)\n",
    "text_reviews_f = flatten_data(all_text_reviews)\n",
    "ratings_f = flatten_data(all_ratings)\n",
    "time_reviews_f = flatten_data(clean_time_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_prof_df = pd.DataFrame(ext_profiles_f,columns=['Country','Username','Reviews','Reads','Useful','Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_df = pd.DataFrame(title_reviews_f,columns=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame(text_reviews_f,columns=['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rating_df = pd.DataFrame(ratings_f,columns=['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(time_reviews_f,columns=['day','month','year','hour','minute',\n",
    "                                           'second','dayofweek','weekofyear',\n",
    "                                           'raw time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([review_df, title_df, rating_df,time_df, ext_prof_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review', 'Title', 'Rating', 'day', 'month', 'year', 'hour', 'minute',\n",
       "       'second', 'dayofweek', 'weekofyear', 'raw time', 'Country', 'Username',\n",
       "       'Reviews', 'Reads', 'Useful', 'Genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv('rebtel.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract profiles from all users\n",
    "profile_links = []\n",
    "website = 'https://www.trustpilot.com/'\n",
    "page_profiles = []\n",
    "\n",
    "#get profile links\n",
    "for profile in all_reviews[0][2]:\n",
    "    tmp_prof_link = website + profile.attrs['href']\n",
    "    profile_links.append(tmp_prof_link) \n",
    "\n",
    "for link in profile_links:\n",
    "    \n",
    "    html = requests.get(link).text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    tmp_summ = soup.find(\"div\",{\"class\": 'user-summary-gender-location'})\n",
    "    country = tmp_summ.contents[-2].contents[0]\n",
    "    \n",
    "    tmp_name = soup.find(\"h1\",{\"class\": 'user-summary-info__user-name'})\n",
    "    user_name = tmp_name.contents[0]\n",
    "    \n",
    "    tmp_rev = soup.find(\"span\",{\"class\": 'user-reviews-stats__reviewcount'})\n",
    "    num_rev = tmp_rev.attrs['data-count']\n",
    "    \n",
    "    tmp_reads = soup.find(\"span\",{\"class\": 'user-reviews-stats__readcount'})\n",
    "    num_reads = tmp_reads.attrs['data-count']\n",
    "    \n",
    "    tmp_useful = soup.find(\"span\",{\"class\": 'user-reviews-stats__usefulcount'})\n",
    "    num_useful = tmp_useful.attrs['data-count']\n",
    "    \n",
    "    tmp_genre = soup.find(\"div\",{\"class\": 'user-summary-gender'})\n",
    "    genre = tmp_genre.contents[0]\n",
    "    \n",
    "    profile_data = [country, user_name, num_rev, num_reads, num_useful, genre]\n",
    "    \n",
    "    page_profiles.append(profile_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "detailed_profiles[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = profile_links[0]\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_summ = soup.find(\"div\",{\"class\": 'user-summary-gender-location'})\n",
    "country = tmp_summ.contents[-2].contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_name = soup.find(\"h1\",{\"class\": 'user-summary-info__user-name'})\n",
    "user_name = tmp_name.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_rev = soup.find(\"span\",{\"class\": 'user-reviews-stats__reviewcount'})\n",
    "num_rev = tmp_rev.attrs['data-count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_reads = soup.find(\"span\",{\"class\": 'user-reviews-stats__readcount'})\n",
    "num_reads = tmp_reads.attrs['data-count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_useful = soup.find(\"span\",{\"class\": 'user-reviews-stats__usefulcount'})\n",
    "num_useful = tmp_useful.attrs['data-count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_genre = soup.find(\"div\",{\"class\": 'user-summary-gender'})\n",
    "genre = tmp_genre.contents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profile_data = [country, user_name, num_rev, num_reads, num_useful, genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = \"https://www.trustpilot.com/review/www.rebtel.com\"\n",
    "\n",
    "html = requests.get(link).text\n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#soup.findAll(\"div\",{\"class\": 'review-body'})\n",
    "soup.findAll(\"div\",{\"class\": 'text useful-counter-js hidden'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#soup.find(\"div\", {'class': 'companyinformation-wrapper clearfix'})\n",
    "soup.findAll(\"a\",{\"class\": 'user-review-name-link'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = \"https://www.architecture.com/FindAnArchitect/FAAPractices.aspx?display=50\"\n",
    "\n",
    "html = requests.get(link).text\n",
    "\n",
    "\"\"\"If you do not want to use requests then you can use the following code below \n",
    "   with urllib (the snippet above). It should not cause any issue.\"\"\"\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "res = soup.findAll(\"article\", {\"class\": \"listingItem\"})\n",
    "for r in res:\n",
    "    print(\"Company Name: \" + r.find('a').text)\n",
    "    print(\"Address: \" + r.find(\"div\", {'class': 'address'}).text)\n",
    "    print(\"Website: \" + r.find_all(\"div\", {'class': 'pageMeta-item'})[3].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
